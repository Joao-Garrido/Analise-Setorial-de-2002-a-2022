{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risco Político em Anos Eleitorais no Brasil (2002–2022)\n## Metodologia: Fama-French 3 Fatores + BHAR\n\nRestruturação completa do estudo com:\n- Janelas dinâmicas baseadas no HGPE\n- Modelo FF3 (NEFIN-USP)\n- BHAR (Buy-and-Hold Abnormal Return)\n- Ponderação Value-Weighted\n- Testes: t-Student, Wilcoxon, Placebo, DiD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, warnings, logging, time\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\nwarnings.filterwarnings(\"ignore\")\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\nlog = logging.getLogger(__name__)\nprint(\"✓ Bibliotecas carregadas\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração e Constantes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# CONSTANTES\n# =============================================================================\n\nOUTPUT_DIR = \"./output_ff3_bhar\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Datas do HGPE (início do Horário Gratuito de Propaganda Eleitoral)\nDATAS_HGPE = {\n    2002: pd.Timestamp(\"2002-08-20\"), 2006: pd.Timestamp(\"2006-08-15\"),\n    2010: pd.Timestamp(\"2010-08-17\"), 2014: pd.Timestamp(\"2014-08-19\"),\n    2018: pd.Timestamp(\"2018-08-31\"), 2022: pd.Timestamp(\"2022-08-26\"),\n}\n\n# Datas do 1º turno\nDATAS_PRIMEIRO_TURNO = {\n    2002: pd.Timestamp(\"2002-10-06\"), 2006: pd.Timestamp(\"2006-10-01\"),\n    2010: pd.Timestamp(\"2010-10-03\"), 2014: pd.Timestamp(\"2014-10-05\"),\n    2018: pd.Timestamp(\"2018-10-07\"), 2022: pd.Timestamp(\"2022-10-02\"),\n}\n\n# Anos e datas de Placebo\nANOS_PLACEBO = [2003, 2007, 2011, 2013, 2017, 2019]\nDATAS_HGPE_PLACEBO = {\n    2003: pd.Timestamp(\"2003-08-20\"), 2007: pd.Timestamp(\"2007-08-15\"),\n    2011: pd.Timestamp(\"2011-08-17\"), 2013: pd.Timestamp(\"2013-08-19\"),\n    2017: pd.Timestamp(\"2017-08-31\"), 2019: pd.Timestamp(\"2019-08-26\"),\n}\nDATAS_PRIMEIRO_TURNO_PLACEBO = {\n    2003: pd.Timestamp(\"2003-10-05\"), 2007: pd.Timestamp(\"2007-10-07\"),\n    2011: pd.Timestamp(\"2011-10-02\"), 2013: pd.Timestamp(\"2013-10-06\"),\n    2017: pd.Timestamp(\"2017-10-01\"), 2019: pd.Timestamp(\"2019-10-06\"),\n}\n\n# Classificação para DiD\nSETORES_REGULADOS = [\"Petróleo, Gás e Biocombustíveis\", \"Utilidade Pública\", \"Financeiro\"]\n\n# Parâmetros\nJANELA_ESTIMACAO_DU = 252\nGAP_SEGURANCA_DU = 30\nMIN_OBS_REGRESSAO = 60\nMIN_EMPRESAS_SETOR = 1\nMIN_PREGOES_PCT = 0.40\n\nprint(\"✓ Constantes definidas\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento de Dados\n\n**IMPORTANTE:** Você precisa ter os arquivos de preços e volumes. Se ainda não os tem, rode a célula de download via yfinance abaixo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# CARREGAMENTO DOS FATORES NEFIN\n# =============================================================================\n\ndf_nefin_raw = pd.read_csv(\"nefin_factors.csv\", index_col=0)\ndf_nefin_raw[\"Date\"] = pd.to_datetime(df_nefin_raw[\"Date\"])\ndf_nefin = df_nefin_raw.set_index(\"Date\").sort_index()\ndf_nefin = df_nefin.rename(columns={\"Risk_Free\": \"Rf\"})\ndf_nefin = df_nefin[[\"Rm_minus_Rf\", \"SMB\", \"HML\", \"Rf\"]]\n\nprint(f\"✓ NEFIN: {len(df_nefin)} obs, {df_nefin.index.min().date()} a {df_nefin.index.max().date()}\")\ndf_nefin.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# CARREGAMENTO DE EMPRESAS\n# =============================================================================\n\ndf_empresas = pd.read_excel(\"resultados_analise_b3_com_tickers.xlsx\",\n                             sheet_name=\"LISTA FINAL (Cont+IPOs-Canc)\")\ndf_empresas = df_empresas.dropna(subset=[\"TICKER\", \"SETOR_B3\"])\ndf_empresas[\"DT_REG\"] = pd.to_datetime(df_empresas[\"DT_REG\"], errors=\"coerce\")\n\nprint(f\"✓ {len(df_empresas)} empresas, {df_empresas['SETOR_B3'].nunique()} setores\")\nprint(df_empresas[\"SETOR_B3\"].value_counts())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# DOWNLOAD DE PREÇOS E VOLUMES (yfinance)\n# Rode esta célula apenas uma vez; depois use os CSVs salvos.\n# =============================================================================\n\nimport yfinance as yf\n\ntickers = df_empresas[\"TICKER\"].unique().tolist()\ntickers_yf = [t + \".SA\" for t in tickers]\n\nprint(f\"Baixando {len(tickers_yf)} tickers...\")\ndata = yf.download(tickers_yf, start=\"2000-01-01\", end=\"2023-12-31\",\n                    group_by=\"ticker\", auto_adjust=True, threads=True)\n\n# Extrair preços e volumes\ndf_precos = pd.DataFrame()\ndf_volumes = pd.DataFrame()\n\nfor t_yf, t_b3 in zip(tickers_yf, tickers):\n    try:\n        df_precos[t_b3] = data[t_yf][\"Close\"]\n        df_volumes[t_b3] = data[t_yf][\"Volume\"] * data[t_yf][\"Close\"]  # Volume financeiro\n    except:\n        pass\n\ndf_precos.to_csv(\"precos.csv\")\ndf_volumes.to_csv(\"volumes.csv\")\nprint(f\"✓ Preços: {df_precos.shape}, Volumes: {df_volumes.shape}\")\nprint(\"  Salvos em precos.csv e volumes.csv\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# OU: CARREGUE DE CSVs JÁ SALVOS\n# =============================================================================\n\n# df_precos = pd.read_csv(\"precos.csv\", index_col=0, parse_dates=True)\n# df_volumes = pd.read_csv(\"volumes.csv\", index_col=0, parse_dates=True)\n# print(f\"✓ Preços: {df_precos.shape}, Volumes: {df_volumes.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# RETORNOS LOGARÍTMICOS\n# =============================================================================\n\ndf_retornos = np.log(df_precos / df_precos.shift(1)).dropna(how=\"all\")\nprint(f\"✓ Retornos: {df_retornos.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funções Núcleo: Janelas, FF3, BHAR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# DEFINIÇÃO DINÂMICA DE JANELAS\n# =============================================================================\n\ndef definir_janelas(ano, bdates, datas_hgpe=None, datas_1turno=None):\n    \"\"\"\n    Define janelas de estimação e evento para um dado ano.\n    Janela de Evento: do HGPE até a véspera do 1º turno.\n    Janela de Estimação: 252 DU, encerrando 30 DU antes do HGPE.\n    \"\"\"\n    if datas_hgpe is None: datas_hgpe = DATAS_HGPE\n    if datas_1turno is None: datas_1turno = DATAS_PRIMEIRO_TURNO\n\n    if ano not in datas_hgpe or ano not in datas_1turno:\n        return None\n\n    hgpe = datas_hgpe[ano]\n    turno1 = datas_1turno[ano]\n    bdays = bdates.sort_values()\n\n    evt_inicio_idx = bdays.searchsorted(hgpe, side=\"left\")\n    if evt_inicio_idx >= len(bdays): return None\n    evt_inicio = bdays[evt_inicio_idx]\n\n    evt_fim_idx = bdays.searchsorted(turno1, side=\"left\") - 1\n    if evt_fim_idx < 0: return None\n    evt_fim = bdays[evt_fim_idx]\n\n    est_fim_idx = evt_inicio_idx - GAP_SEGURANCA_DU\n    if est_fim_idx < 0: return None\n    est_fim = bdays[max(0, est_fim_idx)]\n\n    est_inicio_idx = est_fim_idx - JANELA_ESTIMACAO_DU\n    if est_inicio_idx < 0: return None\n    est_inicio = bdays[max(0, est_inicio_idx)]\n\n    return {\n        \"est_inicio\": est_inicio, \"est_fim\": est_fim,\n        \"evt_inicio\": evt_inicio, \"evt_fim\": evt_fim, \"ano\": ano,\n    }\n\n# Teste rápido\nbdates_test = df_retornos.index.sort_values()\nfor ano in sorted(DATAS_HGPE.keys()):\n    j = definir_janelas(ano, bdates_test)\n    if j:\n        print(f\"{ano}: Estimação [{j['est_inicio'].date()} → {j['est_fim'].date()}]  \"\n              f\"Evento [{j['evt_inicio'].date()} → {j['evt_fim'].date()}]\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# CALCULAR BHAR POR ATIVO (FF3)\n# =============================================================================\n\ndef calcular_bhar_ativo(ticker, ano, df_retornos, df_nefin, bdates,\n                        datas_hgpe=None, datas_1turno=None):\n    \"\"\"\n    Calcula BHAR de um ativo:\n      1. Define janelas dinâmicas (HGPE)\n      2. OLS(FF3) na janela de estimação\n      3. Prediz retorno esperado na janela de evento\n      4. BHAR = prod(1+Ri) - prod(1+E[Ri])\n    \"\"\"\n    if datas_hgpe is None: datas_hgpe = DATAS_HGPE\n    if datas_1turno is None: datas_1turno = DATAS_PRIMEIRO_TURNO\n\n    janelas = definir_janelas(ano, bdates, datas_hgpe, datas_1turno)\n    if janelas is None: return None\n    if ticker not in df_retornos.columns: return None\n\n    ret_ativo = df_retornos[ticker].dropna()\n\n    # --- Janela de Estimação ---\n    mask_est = (ret_ativo.index >= janelas[\"est_inicio\"]) & (ret_ativo.index <= janelas[\"est_fim\"])\n    ret_est = ret_ativo.loc[mask_est]\n    n_esperado = len(bdates[(bdates >= janelas[\"est_inicio\"]) & (bdates <= janelas[\"est_fim\"])])\n    if len(ret_est) < max(MIN_OBS_REGRESSAO, int(n_esperado * MIN_PREGOES_PCT)):\n        return None\n\n    fac_est = df_nefin.loc[df_nefin.index.isin(ret_est.index)]\n    common_est = ret_est.index.intersection(fac_est.index)\n    if len(common_est) < MIN_OBS_REGRESSAO: return None\n\n    ret_est = ret_est.loc[common_est]\n    fac_est = fac_est.loc[common_est]\n\n    # Regressão: Ri - Rf = α + β1(Rm-Rf) + β2·SMB + β3·HML + ε\n    y = ret_est - fac_est[\"Rf\"]\n    X = sm.add_constant(fac_est[[\"Rm_minus_Rf\", \"SMB\", \"HML\"]])\n    try:\n        modelo = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 5})\n    except:\n        return None\n    betas = modelo.params\n\n    # --- Janela de Evento ---\n    mask_evt = (ret_ativo.index >= janelas[\"evt_inicio\"]) & (ret_ativo.index <= janelas[\"evt_fim\"])\n    ret_evt = ret_ativo.loc[mask_evt]\n    fac_evt = df_nefin.loc[df_nefin.index.isin(ret_evt.index)]\n    common_evt = ret_evt.index.intersection(fac_evt.index)\n    if len(common_evt) < 5: return None\n\n    ret_evt = ret_evt.loc[common_evt]\n    fac_evt = fac_evt.loc[common_evt]\n\n    # E[Ri,t] = α̂ + β̂·X_t + Rf_t\n    X_evt = sm.add_constant(fac_evt[[\"Rm_minus_Rf\", \"SMB\", \"HML\"]])\n    ret_esperado = X_evt.dot(betas) + fac_evt[\"Rf\"]\n\n    # BHAR\n    bhar_real = (1 + ret_evt).prod()\n    bhar_esp = (1 + ret_esperado).prod()\n    if np.isnan(bhar_real) or np.isnan(bhar_esp) or bhar_esp == 0: return None\n\n    return {\n        \"ticker\": ticker, \"ano\": ano,\n        \"bhar\": bhar_real - bhar_esp,\n        \"n_obs_est\": len(common_est), \"n_obs_evt\": len(common_evt),\n        \"r2\": modelo.rsquared,\n        \"alpha\": betas.get(\"const\", np.nan),\n        \"beta_mkt\": betas.get(\"Rm_minus_Rf\", np.nan),\n        \"beta_smb\": betas.get(\"SMB\", np.nan),\n        \"beta_hml\": betas.get(\"HML\", np.nan),\n    }\n\nprint(\"✓ calcular_bhar_ativo definida\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# PROCESSAR SETOR (AGREGAÇÃO VALUE-WEIGHTED)\n# =============================================================================\n\ndef processar_setor(setor, ano, tickers_setor, df_retornos, df_volumes,\n                    df_nefin, bdates, datas_hgpe=None, datas_1turno=None):\n    \"\"\"\n    Agrega BHARs de um setor com pesos VW (volume na janela de estimação).\n    Retorna ABHAR_VW, ABHAR_EW, testes t e Wilcoxon.\n    \"\"\"\n    if datas_hgpe is None: datas_hgpe = DATAS_HGPE\n    if datas_1turno is None: datas_1turno = DATAS_PRIMEIRO_TURNO\n\n    resultados_ativos = []\n    for ticker in tickers_setor:\n        res = calcular_bhar_ativo(ticker, ano, df_retornos, df_nefin, bdates,\n                                  datas_hgpe, datas_1turno)\n        if res is not None:\n            resultados_ativos.append(res)\n\n    if len(resultados_ativos) < MIN_EMPRESAS_SETOR:\n        return None\n\n    df_res = pd.DataFrame(resultados_ativos)\n    bhars = df_res[\"bhar\"].values\n\n    # Pesos VW\n    janelas = definir_janelas(ano, bdates, datas_hgpe, datas_1turno)\n    if janelas is None: return None\n\n    pesos = []\n    for _, row in df_res.iterrows():\n        tk = row[\"ticker\"]\n        if tk in df_volumes.columns:\n            vol_est = df_volumes.loc[\n                (df_volumes.index >= janelas[\"est_inicio\"]) &\n                (df_volumes.index <= janelas[\"est_fim\"]), tk\n            ]\n            pesos.append(max(vol_est.mean() if len(vol_est) > 0 else 0, 0))\n        else:\n            pesos.append(0)\n\n    pesos = np.array(pesos, dtype=float)\n    if pesos.sum() == 0: pesos = np.ones(len(pesos))\n    pesos_norm = pesos / pesos.sum()\n\n    abhar_vw = np.dot(pesos_norm, bhars)\n    abhar_ew = np.mean(bhars)\n\n    # Testes estatísticos\n    p_ttest = p_wilcoxon = np.nan\n    if len(bhars) >= 2:\n        try: _, p_ttest = stats.ttest_1samp(bhars, 0)\n        except: pass\n    if len(bhars) >= 5:\n        try: _, p_wilcoxon = stats.wilcoxon(bhars, alternative=\"two-sided\")\n        except: pass\n\n    return {\n        \"setor\": setor, \"ano\": ano,\n        \"abhar_vw\": abhar_vw, \"abhar_ew\": abhar_ew,\n        \"n_ativos\": len(bhars),\n        \"bhar_medio\": np.mean(bhars), \"bhar_mediana\": np.median(bhars),\n        \"bhar_std\": np.std(bhars, ddof=1) if len(bhars) > 1 else np.nan,\n        \"p_ttest\": p_ttest, \"p_wilcoxon\": p_wilcoxon,\n        \"tickers_validos\": df_res[\"ticker\"].tolist(),\n        \"r2_medio\": df_res[\"r2\"].mean(),\n    }\n\nprint(\"✓ processar_setor definida\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execução: Mapa de Risco Eleitoral"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n# GERAR MAPA DE RISCO\n# =============================================================================\n\ndef gerar_mapa_risco(df_retornos, df_volumes, df_nefin, df_empresas,\n                     anos=None, datas_hgpe=None, datas_1turno=None, label=\"Eleitoral\"):\n    if anos is None: anos = sorted(DATAS_HGPE.keys())\n    if datas_hgpe is None: datas_hgpe = DATAS_HGPE\n    if datas_1turno is None: datas_1turno = DATAS_PRIMEIRO_TURNO\n\n    bdates = df_retornos.index.sort_values()\n    setores = df_empresas.groupby(\"SETOR_B3\")[\"TICKER\"].apply(list).to_dict()\n\n    resultados = []\n    for ano in anos:\n        if ano not in datas_hgpe:\n            print(f\"  ⚠ Ano {ano} sem HGPE, pulando.\")\n            continue\n        print(f\"  Processando {ano}...\")\n        for setor, tickers in setores.items():\n            res = processar_setor(setor, ano, tickers, df_retornos, df_volumes,\n                                  df_nefin, bdates, datas_hgpe, datas_1turno)\n            if res is not None:\n                res[\"tipo\"] = label\n                resultados.append(res)\n                sig = \"***\" if res[\"p_ttest\"]<0.01 else (\"**\" if res[\"p_ttest\"]<0.05 else (\"*\" if res[\"p_ttest\"]<0.10 else \"\"))\n                print(f\"    {setor}: ABHAR_VW={res['abhar_vw']:+.4f}, N={res['n_ativos']}, p={res['p_ttest']:.4f} {sig}\")\n\n    return pd.DataFrame(resultados)\n\n# ---- EXECUTAR ----\nprint(\"=\" * 70)\nprint(\"MAPA DE RISCO — ANOS ELEITORAIS (2002–2022)\")\nprint(\"=\" * 70)\ndf_eleitoral = gerar_mapa_risco(df_retornos, df_volumes, df_nefin, df_empresas)\nprint(f\"\\n✓ {len(df_eleitoral)} observações setor×ano\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Heatmap Eleitoral"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nhm_data = df_eleitoral.pivot_table(index=\"setor\", columns=\"ano\", values=\"abhar_vw\", aggfunc=\"first\")\n\nfig, ax = plt.subplots(figsize=(14, 8))\nsns.heatmap(hm_data * 100, annot=True, fmt=\".2f\", cmap=\"RdYlGn_r\",\n            center=0, linewidths=0.5, ax=ax, cbar_kws={\"label\": \"ABHAR (%)\"})\nax.set_title(\"Mapa de Risco Político Setorial — ABHAR (FF3, VW)\\nAnos Eleitorais 2002–2022\", fontsize=14)\nax.set_ylabel(\"Setor B3\")\nax.set_xlabel(\"Ano Eleitoral\")\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, \"heatmap_eleitoral.png\"), dpi=300)\nplt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Teste Placebo (Anos Não-Eleitorais)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\nprint(\"TESTE PLACEBO — ANOS NÃO-ELEITORAIS\")\nprint(\"=\" * 70)\ndf_placebo = gerar_mapa_risco(\n    df_retornos, df_volumes, df_nefin, df_empresas,\n    anos=ANOS_PLACEBO,\n    datas_hgpe=DATAS_HGPE_PLACEBO,\n    datas_1turno=DATAS_PRIMEIRO_TURNO_PLACEBO,\n    label=\"Placebo\",\n)\nprint(f\"\\n✓ {len(df_placebo)} observações placebo\")\n\n# Heatmap Placebo\nhm_placebo = df_placebo.pivot_table(index=\"setor\", columns=\"ano\", values=\"abhar_vw\", aggfunc=\"first\")\nif not hm_placebo.empty:\n    fig, ax = plt.subplots(figsize=(14, 8))\n    sns.heatmap(hm_placebo * 100, annot=True, fmt=\".2f\", cmap=\"RdYlGn_r\",\n                center=0, linewidths=0.5, ax=ax, cbar_kws={\"label\": \"ABHAR (%)\"})\n    ax.set_title(\"Teste Placebo — ABHAR (FF3, VW)\\nAnos Não-Eleitorais\", fontsize=14)\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"heatmap_placebo.png\"), dpi=300)\n    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Difference-in-Differences (Regulados vs Não Regulados)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def gerar_diff_in_diff(df_resultados):\n    df = df_resultados.copy()\n    df[\"grupo\"] = df[\"setor\"].apply(lambda s: \"Regulado\" if s in SETORES_REGULADOS else \"Não Regulado\")\n\n    resultados_did = []\n    for ano in sorted(df[\"ano\"].unique()):\n        df_ano = df[df[\"ano\"] == ano]\n        reg = df_ano[df_ano[\"grupo\"] == \"Regulado\"][\"abhar_vw\"]\n        nreg = df_ano[df_ano[\"grupo\"] == \"Não Regulado\"][\"abhar_vw\"]\n        if len(reg) == 0 or len(nreg) == 0: continue\n\n        diff = reg.mean() - nreg.mean()\n        p_val = np.nan\n        if len(reg) >= 2 and len(nreg) >= 2:\n            try: _, p_val = stats.ttest_ind(reg, nreg, equal_var=False)\n            except: pass\n\n        resultados_did.append({\n            \"ano\": ano, \"abhar_regulados\": reg.mean(),\n            \"abhar_nao_regulados\": nreg.mean(), \"diff\": diff,\n            \"n_reg\": len(reg), \"n_nreg\": len(nreg), \"p_value\": p_val,\n        })\n\n    df_did = pd.DataFrame(resultados_did)\n    if not df_did.empty:\n        media = {\"ano\": \"Média\", \"abhar_regulados\": df_did[\"abhar_regulados\"].mean(),\n                 \"abhar_nao_regulados\": df_did[\"abhar_nao_regulados\"].mean(),\n                 \"diff\": df_did[\"diff\"].mean(), \"n_reg\": \"\", \"n_nreg\": \"\", \"p_value\": np.nan}\n        df_did = pd.concat([df_did, pd.DataFrame([media])], ignore_index=True)\n    return df_did\n\ndf_did = gerar_diff_in_diff(df_eleitoral)\nprint(\"\\nDifference-in-Differences:\")\nprint(df_did.to_string(index=False))\n\n# Gráfico DiD\nif not df_did.empty:\n    df_plot = df_did[df_did[\"ano\"] != \"Média\"].copy()\n    df_plot[\"ano\"] = df_plot[\"ano\"].astype(int)\n    fig, ax = plt.subplots(figsize=(10, 6))\n    x = np.arange(len(df_plot))\n    w = 0.35\n    ax.bar(x - w/2, df_plot[\"abhar_regulados\"]*100, w, label=\"Regulados\", color=\"#d62728\")\n    ax.bar(x + w/2, df_plot[\"abhar_nao_regulados\"]*100, w, label=\"Não Regulados\", color=\"#1f77b4\")\n    ax.set_xticks(x); ax.set_xticklabels(df_plot[\"ano\"])\n    ax.set_ylabel(\"ABHAR Médio (%)\"); ax.set_title(\"DiD: Regulados vs Não Regulados\")\n    ax.legend(); ax.axhline(0, color=\"black\", lw=0.8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"did_barras.png\"), dpi=300)\n    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exportação dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exportar tudo para Excel\nwith pd.ExcelWriter(os.path.join(OUTPUT_DIR, \"resultados_ff3_bhar.xlsx\"), engine=\"openpyxl\") as writer:\n    df_eleitoral.to_excel(writer, sheet_name=\"Eleitoral_Detalhado\", index=False)\n    hm_data.to_excel(writer, sheet_name=\"Heatmap_Eleitoral\")\n\n    sig = df_eleitoral[[\"setor\",\"ano\",\"abhar_vw\",\"p_ttest\",\"p_wilcoxon\",\"n_ativos\"]].copy()\n    sig[\"sig_ttest\"] = sig[\"p_ttest\"].apply(\n        lambda p: \"***\" if p<0.01 else (\"**\" if p<0.05 else (\"*\" if p<0.10 else \"\")))\n    sig.to_excel(writer, sheet_name=\"Significancia\", index=False)\n\n    if not df_placebo.empty:\n        df_placebo.to_excel(writer, sheet_name=\"Placebo_Detalhado\", index=False)\n        hm_placebo.to_excel(writer, sheet_name=\"Heatmap_Placebo\")\n\n    df_did.to_excel(writer, sheet_name=\"DiD\", index=False)\n\nprint(f\"✓ Resultados salvos em {OUTPUT_DIR}/resultados_ff3_bhar.xlsx\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumo da Significância Estatística"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Tabela resumo\nif not df_eleitoral.empty:\n    resumo = df_eleitoral.groupby(\"setor\").agg(\n        ABHAR_medio=(\"abhar_vw\", \"mean\"),\n        ABHAR_mediano=(\"abhar_vw\", \"median\"),\n        N_obs=(\"n_ativos\", \"sum\"),\n        p_ttest_medio=(\"p_ttest\", \"mean\"),\n        anos_sig_5pct=(\"p_ttest\", lambda x: (x < 0.05).sum()),\n    ).sort_values(\"ABHAR_medio\")\n\n    resumo[\"ABHAR_medio\"] = resumo[\"ABHAR_medio\"].map(\"{:+.4f}\".format)\n    resumo[\"ABHAR_mediano\"] = resumo[\"ABHAR_mediano\"].map(\"{:+.4f}\".format)\n    print(\"\\n\" + \"=\" * 70)\n    print(\"RESUMO POR SETOR (Média ao longo dos anos eleitorais)\")\n    print(\"=\" * 70)\n    print(resumo.to_string())"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}